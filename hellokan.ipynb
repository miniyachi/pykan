{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "134e7f9d",
   "metadata": {},
   "source": [
    "# Hello, KAN!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cf5cd0",
   "metadata": {},
   "source": [
    "### Kolmogorov-Arnold representation theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88e5321",
   "metadata": {},
   "source": [
    "Kolmogorov-Arnold representation theorem states that if $f$ is a multivariate continuous function\n",
    "on a bounded domain, then it can be written as a finite composition of continuous functions of a\n",
    "single variable and the binary operation of addition. More specifically, for a smooth $f : [0,1]^n \\to \\mathbb{R}$,\n",
    "\n",
    "\n",
    "$$f(x) = f(x_1,...,x_n)=\\sum_{q=1}^{2n+1}\\Phi_q(\\sum_{p=1}^n \\phi_{q,p}(x_p))$$\n",
    "\n",
    "where $\\phi_{q,p}:[0,1]\\to\\mathbb{R}$ and $\\Phi_q:\\mathbb{R}\\to\\mathbb{R}$. In a sense, they showed that the only true multivariate function is addition, since every other function can be written using univariate functions and sum. However, this 2-Layer width-$(2n+1)$ Kolmogorov-Arnold representation may not be smooth due to its limited expressive power. We augment its expressive power by generalizing it to arbitrary depths and widths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd8766a",
   "metadata": {},
   "source": [
    "### Kolmogorov-Arnold Network (KAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf3b1ee",
   "metadata": {},
   "source": [
    "The Kolmogorov-Arnold representation can be written in matrix form\n",
    "\n",
    "$$f(x)={\\bf \\Phi}_{\\rm out}\\circ{\\bf \\Phi}_{\\rm in}\\circ {\\bf x}$$\n",
    "\n",
    "where \n",
    "\n",
    "$${\\bf \\Phi}_{\\rm in}= \\begin{pmatrix} \\phi_{1,1}(\\cdot) & \\cdots & \\phi_{1,n}(\\cdot) \\\\ \\vdots & & \\vdots \\\\ \\phi_{2n+1,1}(\\cdot) & \\cdots & \\phi_{2n+1,n}(\\cdot) \\end{pmatrix},\\quad {\\bf \\Phi}_{\\rm out}=\\begin{pmatrix} \\Phi_1(\\cdot) & \\cdots & \\Phi_{2n+1}(\\cdot)\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6521452",
   "metadata": {},
   "source": [
    "We notice that both ${\\bf \\Phi}_{\\rm in}$ and ${\\bf \\Phi}_{\\rm out}$ are special cases of the following function matrix ${\\bf \\Phi}$ (with $n_{\\rm in}$ inputs, and $n_{\\rm out}$ outputs), we call a Kolmogorov-Arnold layer:\n",
    "\n",
    "$${\\bf \\Phi}= \\begin{pmatrix} \\phi_{1,1}(\\cdot) & \\cdots & \\phi_{1,n_{\\rm in}}(\\cdot) \\\\ \\vdots & & \\vdots \\\\ \\phi_{n_{\\rm out},1}(\\cdot) & \\cdots & \\phi_{n_{\\rm out},n_{\\rm in}}(\\cdot) \\end{pmatrix}$$\n",
    "\n",
    "${\\bf \\Phi}_{\\rm in}$ corresponds to $n_{\\rm in}=n, n_{\\rm out}=2n+1$, and ${\\bf \\Phi}_{\\rm out}$ corresponds to $n_{\\rm in}=2n+1, n_{\\rm out}=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b410498",
   "metadata": {},
   "source": [
    "After defining the layer, we can construct a Kolmogorov-Arnold network simply by stacking layers! Let's say we have $L$ layers, with the $l^{\\rm th}$ layer ${\\bf \\Phi}_l$ have shape $(n_{l+1}, n_{l})$. Then the whole network is\n",
    "\n",
    "$${\\rm KAN}({\\bf x})={\\bf \\Phi}_{L-1}\\circ\\cdots \\circ{\\bf \\Phi}_1\\circ{\\bf \\Phi}_0\\circ {\\bf x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bbde9a",
   "metadata": {},
   "source": [
    "In constrast, a Multi-Layer Perceptron is interleaved by linear layers ${\\bf W}_l$ and nonlinearities $\\sigma$:\n",
    "\n",
    "$${\\rm MLP}({\\bf x})={\\bf W}_{L-1}\\circ\\sigma\\circ\\cdots\\circ {\\bf W}_1\\circ\\sigma\\circ {\\bf W}_0\\circ {\\bf x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5f7795",
   "metadata": {},
   "source": [
    "A KAN can be easily visualized. (1) A KAN is simply stack of KAN layers. (2) Each KAN layer can be visualized as a fully-connected layer, with a 1D function placed on each edge. Let's see an example below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcb5f75",
   "metadata": {},
   "source": [
    "### Get started with KANs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2571d531",
   "metadata": {},
   "source": [
    "Initialize KAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2075ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kan import *\n",
    "# create a KAN: 2D inputs, 1D output, and 5 hidden neurons. cubic spline (k=3), 5 grid intervals (grid=5).\n",
    "model = KAN(width=[2,5,1], grid=5, k=3, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d72e076",
   "metadata": {},
   "source": [
    "Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46717e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset f(x,y) = exp(sin(pi*x)+y^2)\n",
    "f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n",
    "dataset = create_dataset(f, n_var=2)\n",
    "dataset['train_input'].shape, dataset['train_label'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6add1d",
   "metadata": {},
   "source": [
    "Plot KAN at initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac76f858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot KAN at initialization\n",
    "model(dataset['train_input']);\n",
    "model.plot(beta=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d09096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params save stem\n",
    "dir_stem = 'params'\n",
    "os.makedirs(dir_stem, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec25ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the initial parameters\n",
    "theta0 = model.state_dict().copy()\n",
    "torch.save(theta0, os.path.join(dir_stem, 'theta0.pth'))\n",
    "print('Saved initial parameters to', os.path.join(dir_stem, 'theta0.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf67e30",
   "metadata": {},
   "source": [
    "Train KAN with sparsity regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97111d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model.train_model(dataset, opt=\"LBFGS\", steps=20, lamb=0.01, lamb_entropy=10.);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f30c3ab",
   "metadata": {},
   "source": [
    "Plot trained KAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f95fcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e014705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the initial parameters\n",
    "thetaN = model.state_dict().copy()\n",
    "torch.save(thetaN, os.path.join(dir_stem, 'thetaN.pth'))\n",
    "print('Saved final parameters to', os.path.join(dir_stem, 'thetaN.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d537b7",
   "metadata": {},
   "source": [
    "Prune KAN and replot (keep the original shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1269a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prune()\n",
    "model.plot(mask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576856cf",
   "metadata": {},
   "source": [
    "Prune KAN and replot (get a smaller shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe6fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.prune()\n",
    "model(dataset['train_input'])\n",
    "model.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd08ad99",
   "metadata": {},
   "source": [
    "Continue training and replot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a2db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_model(dataset, opt=\"LBFGS\", steps=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf35d505",
   "metadata": {},
   "source": [
    "Automatically or manually set activation functions to be symbolic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c0642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"auto\" # \"manual\"\n",
    "\n",
    "if mode == \"manual\":\n",
    "    # manual mode\n",
    "    model.fix_symbolic(0,0,0,'sin');\n",
    "    model.fix_symbolic(0,1,0,'x^2');\n",
    "    model.fix_symbolic(1,0,0,'exp');\n",
    "elif mode == \"auto\":\n",
    "    # automatic mode\n",
    "    lib = ['x','x^2','x^3','x^4','exp','log','sqrt','tanh','sin','abs']\n",
    "    model.auto_symbolic(lib=lib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821ba616",
   "metadata": {},
   "source": [
    "Continue training to almost machine precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0800415",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_model(dataset, opt=\"LBFGS\", steps=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39da499",
   "metadata": {},
   "source": [
    "Obtain the symbolic formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf44f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.symbolic_formula()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b41c327",
   "metadata": {},
   "source": [
    "## Is KAN convex? \n",
    "No... :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba4b4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kan import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2736bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset f(x,y) = exp(sin(pi*x)+y^2)\n",
    "f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n",
    "dataset = create_dataset(f, n_var=2)\n",
    "dataset['train_input'].shape, dataset['train_label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59daab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load initial and final parameters\n",
    "dir_stem = 'params'\n",
    "theta0 = torch.load(os.path.join(dir_stem, 'theta0.pth'))\n",
    "thetaN = torch.load(os.path.join(dir_stem, 'thetaN.pth'))\n",
    "\n",
    "# Linearly interpolate/extrapolate the parameters between theta0 and thetaN\n",
    "alphas = np.linspace(-1.5, 2.0, 50)\n",
    "thetas = [{name: (1-alpha)*theta0[name] + alpha*thetaN[name] for name in theta0} for alpha in alphas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a26bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model and define the loss\n",
    "model = KAN(width=[2,5,1], grid=5, k=3)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad7233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_datasets = 10\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "for i in range(n_datasets):\n",
    "    # Create a new dataset\n",
    "    dataset = create_dataset(f, n_var=2, seed=i)\n",
    "    data = dataset['train_input']\n",
    "    targets = dataset['train_label']\n",
    "\n",
    "    # Compute the loss for each theta\n",
    "    losses = []\n",
    "    with torch.no_grad():  # No need to compute gradients for evaluation\n",
    "        for theta in thetas:\n",
    "            model.load_state_dict(theta)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    # Plot the loss as a function of alpha\n",
    "    ax.plot(alphas, losses, label=f'Dataset {i}')\n",
    "\n",
    "# add legend for each line\n",
    "ax.legend()\n",
    "\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('MSE loss')\n",
    "plt.title('Interpolation between theta0 and thetaN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be3befd",
   "metadata": {},
   "source": [
    "### Spectrum Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af45226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kan import *\n",
    "from pyhessian import hessian, get_esd_plot # Hessian computation\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a242b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model and define the loss\n",
    "model = KAN(width=[2,5,1], grid=5, k=3)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb92e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset f(x,y) = exp(sin(pi*x)+y^2)\n",
    "f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n",
    "dataset = create_dataset(f, n_var=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "inputs = dataset['train_input']\n",
    "targets = dataset['train_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7274442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = PdfPages('figures/spec_density/kan.pdf')\n",
    "for i, theta in enumerate(thetas):\n",
    "    model.load_state_dict(theta)\n",
    "    hessian_comp = hessian(model, criterion, data=(inputs,targets), cuda=False) \n",
    "    density_eigen, density_weight = hessian_comp.density()\n",
    "    fig, ax = get_esd_plot(density_eigen, density_weight)\n",
    "    ax.set_title(f'Spectrum of Hessian for alpha={alphas[i]:.2f}')\n",
    "    pdf.savefig(fig, bbox_inches = 'tight')\n",
    "    plt.close(fig)\n",
    "pdf.close()        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6f04e4",
   "metadata": {},
   "source": [
    "### Eigvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16226311",
   "metadata": {},
   "outputs": [],
   "source": [
    "hessian_comp = hessian(model, criterion, data=(inputs,targets), cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62101405",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_eigenvalues, top_eigenvector = hessian_comp.eigenvalues()\n",
    "print(\"The top Hessian eigenvalue of this model is %.4f\"%top_eigenvalues[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305c50e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's compute the top 2 eigenavlues and eigenvectors of the Hessian\n",
    "top_eigenvalues, top_eigenvector = hessian_comp.eigenvalues(top_n=5)\n",
    "print(\"The top two eigenvalues of this model are: %.4f %.4f\"% (top_eigenvalues[-1],top_eigenvalues[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ed0f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = hessian_comp.trace()\n",
    "print(\"The trace of this model is: %.4f\"%(np.mean(trace)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217a9ae2",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7213e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mlp import MLP\n",
    "from utils import get_final_dataset\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7057519",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './data'\n",
    "id = '41166'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dd9134b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size:  147\n",
      "Output size:  10\n",
      "Hidden layers:  [512]\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset, input_size, y_train = get_final_dataset(data_folder, id)\n",
    "\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "output_size = n_classes\n",
    "hidden_layers = [512] * 1\n",
    "\n",
    "model = MLP(input_size, output_size, hidden_layers)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Input size: \", input_size)\n",
    "print(\"Output size: \", output_size)\n",
    "print(\"Hidden layers: \", hidden_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da63fc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hidden_layers.0.weight', Parameter containing:\n",
      "tensor([[-0.0625, -0.0451, -0.0572,  ...,  0.0195, -0.0308,  0.0798],\n",
      "        [ 0.0273,  0.0594, -0.0430,  ..., -0.0543, -0.0601, -0.0516],\n",
      "        [ 0.0570, -0.0605, -0.0404,  ..., -0.0569,  0.0216, -0.0678],\n",
      "        ...,\n",
      "        [ 0.0643, -0.0566, -0.0621,  ..., -0.0296,  0.0460, -0.0806],\n",
      "        [ 0.0040,  0.0394, -0.0167,  ...,  0.0114,  0.0195,  0.0399],\n",
      "        [ 0.0396,  0.0744, -0.0017,  ...,  0.0508, -0.0338, -0.0091]],\n",
      "       requires_grad=True))\n",
      "('hidden_layers.0.bias', Parameter containing:\n",
      "tensor([-5.6769e-02, -1.2258e-02, -7.9065e-02, -4.4657e-02,  1.6983e-02,\n",
      "        -1.4582e-02, -1.2332e-02,  6.4829e-03,  5.6622e-02, -2.0920e-02,\n",
      "        -1.7363e-02,  6.1459e-02,  4.1294e-02,  6.0514e-02,  5.2103e-02,\n",
      "        -2.3026e-02, -7.2150e-02,  2.1650e-02, -7.5682e-02, -7.3647e-02,\n",
      "        -4.6706e-02, -5.5821e-02,  5.0276e-02,  7.3004e-02, -6.4359e-02,\n",
      "         5.6887e-02, -3.2981e-02,  1.6293e-02,  1.6006e-02, -9.9190e-03,\n",
      "         5.7037e-03,  5.3664e-02, -4.8902e-02, -2.5136e-02,  3.8887e-02,\n",
      "        -4.0339e-02,  7.8876e-02,  6.3540e-02,  5.9664e-02,  6.0444e-02,\n",
      "        -6.8106e-02,  7.5826e-02, -2.2288e-02, -5.0608e-02, -4.8297e-03,\n",
      "         6.2804e-02, -1.1481e-02,  8.0929e-02,  2.3996e-02,  3.8518e-02,\n",
      "        -3.8693e-02, -4.0730e-02,  6.0036e-02, -7.4537e-02,  3.2998e-02,\n",
      "         6.6674e-02,  3.8023e-02,  1.0923e-02,  7.8971e-02,  6.3522e-02,\n",
      "        -7.1037e-02,  3.5967e-02, -2.0668e-02, -5.4712e-02, -2.6999e-02,\n",
      "        -4.8937e-02, -7.4982e-02, -5.2718e-02,  6.2310e-02,  4.6515e-02,\n",
      "        -5.9757e-02, -3.8244e-02,  6.1175e-03,  4.8472e-02,  3.7483e-03,\n",
      "        -5.8367e-02,  1.6631e-02, -5.9831e-04, -5.6770e-02, -1.3601e-02,\n",
      "         1.9507e-02,  5.9085e-02,  7.2582e-02,  1.3896e-03, -7.6948e-02,\n",
      "         3.6877e-03, -1.5550e-02, -4.4656e-02,  5.6346e-02,  1.8056e-02,\n",
      "         1.8437e-02, -2.0375e-02,  1.9983e-02,  6.0125e-02,  5.0856e-02,\n",
      "        -7.3098e-02,  4.7815e-02, -4.2909e-02, -6.3568e-02, -8.1434e-02,\n",
      "        -1.6273e-02,  4.9087e-02, -6.1646e-02, -4.2286e-02,  3.6615e-02,\n",
      "        -6.5674e-02,  2.6203e-02, -4.0420e-02, -5.5881e-02,  6.2565e-02,\n",
      "         5.2734e-02,  8.1962e-02, -1.6918e-02,  1.8588e-02,  5.9111e-04,\n",
      "         5.8481e-03, -7.9097e-02,  7.0743e-02,  4.0250e-02,  5.6788e-02,\n",
      "        -1.5820e-04,  4.9748e-02,  1.6845e-02,  1.5667e-02, -6.6886e-02,\n",
      "         6.6985e-02,  4.0268e-02, -7.3044e-02, -6.3782e-02, -5.9175e-02,\n",
      "        -5.2332e-02, -7.6641e-02,  1.3529e-02,  6.1336e-02,  3.6525e-02,\n",
      "         6.0562e-02, -1.8965e-02,  7.6057e-02, -9.5489e-03, -6.7150e-02,\n",
      "         1.7602e-02, -8.0168e-02,  1.7681e-02,  8.1760e-02, -7.9817e-02,\n",
      "        -2.3887e-02,  5.1167e-02,  5.8854e-02, -3.2594e-02, -6.9137e-02,\n",
      "        -9.5429e-03,  3.2751e-03,  8.2236e-03, -7.8420e-02, -6.9474e-02,\n",
      "         3.5738e-02,  7.8830e-02,  3.3240e-02, -2.8216e-02,  4.4159e-03,\n",
      "        -6.1551e-02,  5.9146e-02,  1.0244e-02, -1.9357e-02, -1.6255e-02,\n",
      "        -5.5262e-02,  1.4861e-02,  3.0188e-02, -3.8817e-02, -2.7532e-02,\n",
      "        -8.2054e-02,  3.9659e-03,  4.3867e-02, -9.1964e-03,  8.1541e-02,\n",
      "        -8.4701e-03, -5.3748e-02,  3.1191e-02, -3.3930e-02,  5.7700e-02,\n",
      "         3.8079e-02,  1.5551e-02,  6.1726e-02,  7.9328e-02, -4.5016e-02,\n",
      "         3.0545e-02, -1.3352e-03,  6.5143e-02,  4.8089e-02,  6.2359e-02,\n",
      "         1.0224e-03,  8.0537e-03,  2.2028e-02, -7.4968e-03, -7.8842e-02,\n",
      "        -2.0688e-02,  7.5243e-02, -3.6127e-02, -2.2050e-02,  3.4619e-02,\n",
      "         8.0161e-02, -5.5084e-02,  6.7892e-02,  6.4653e-02, -4.9415e-03,\n",
      "         3.2898e-02,  3.9909e-02, -5.3365e-03,  1.5774e-02,  3.7265e-02,\n",
      "        -5.3150e-02,  6.1193e-02,  7.2597e-02,  1.7583e-02,  2.3316e-02,\n",
      "        -1.4395e-02,  1.7520e-02,  1.3464e-02,  7.5175e-02,  5.4079e-02,\n",
      "         2.8369e-02, -5.7578e-03, -6.0024e-02, -6.4078e-02,  6.2208e-02,\n",
      "         8.0591e-02,  7.1570e-02, -3.4110e-03, -5.1396e-02, -5.7239e-02,\n",
      "        -1.2319e-02,  1.7217e-02,  1.6830e-02,  6.6778e-02, -6.3852e-04,\n",
      "        -6.5546e-02, -5.1160e-02, -2.0239e-03,  1.1834e-02,  8.6437e-03,\n",
      "        -4.3144e-03, -5.2172e-02,  1.3633e-02, -5.8581e-02,  1.8951e-02,\n",
      "        -6.4584e-02,  4.0502e-02, -7.3723e-02,  7.4657e-02, -2.1215e-02,\n",
      "         3.3668e-02,  6.0492e-02, -2.6676e-02, -7.0087e-02, -3.0424e-02,\n",
      "        -3.5545e-02,  7.0115e-02, -5.9130e-02,  1.4717e-02, -2.6440e-02,\n",
      "         3.0990e-02,  9.8760e-03,  1.0328e-02, -6.9548e-02, -1.6359e-02,\n",
      "        -7.9330e-02, -3.1892e-02, -6.8549e-02,  5.4924e-02,  5.4175e-02,\n",
      "        -4.2167e-02,  2.3814e-02, -3.7965e-02,  4.8851e-02,  1.5531e-02,\n",
      "         3.2050e-02,  6.8057e-03, -2.8453e-02, -3.4308e-02, -1.9942e-03,\n",
      "        -1.3046e-03,  3.7632e-02,  2.1244e-02,  5.2379e-02,  2.6523e-02,\n",
      "        -8.1768e-02,  9.0067e-03, -2.1067e-02,  1.9139e-02, -4.2045e-02,\n",
      "         6.2362e-02, -5.8558e-02, -1.1441e-02, -2.7433e-02,  6.3995e-02,\n",
      "        -7.8592e-02,  3.5774e-02, -6.8827e-03,  7.0588e-02,  4.8721e-02,\n",
      "        -2.6424e-02,  4.1493e-02,  9.1055e-03, -4.9302e-02,  6.3408e-02,\n",
      "        -5.2574e-02,  1.6483e-02, -6.0700e-02, -7.9012e-02, -1.6356e-02,\n",
      "        -6.5117e-02, -2.3406e-03,  6.3975e-03, -1.0946e-02,  7.9654e-02,\n",
      "         1.1761e-03, -1.6287e-02,  3.5661e-02, -5.6852e-02, -6.8631e-02,\n",
      "         7.8550e-02, -6.7862e-03, -5.9133e-02,  5.5842e-02,  9.0458e-03,\n",
      "        -7.6909e-02, -7.7301e-02,  6.0132e-03, -9.1171e-04,  3.7039e-02,\n",
      "         3.7873e-02, -2.6684e-02, -7.3024e-02, -3.1919e-02,  1.3840e-02,\n",
      "        -7.9028e-02, -6.5640e-03, -2.1845e-02,  4.5995e-02,  6.9393e-02,\n",
      "         3.3013e-02, -1.5123e-02,  5.3726e-02, -7.3929e-02,  5.2726e-02,\n",
      "         4.8339e-02,  7.3771e-02,  8.1122e-03, -6.6755e-02,  3.5276e-02,\n",
      "        -1.9202e-02,  6.3264e-02, -7.2102e-02,  7.1026e-02,  1.8294e-03,\n",
      "         2.8122e-02, -7.5440e-02, -8.8002e-03,  5.9305e-02, -5.8468e-02,\n",
      "         3.4625e-02,  8.2055e-02, -3.8936e-02, -5.0975e-02,  1.7347e-02,\n",
      "        -2.0586e-02, -6.4135e-02,  6.7938e-02,  3.9850e-03, -1.6029e-02,\n",
      "         9.9488e-03,  3.7217e-02, -1.4912e-02, -4.4729e-02, -6.5071e-02,\n",
      "         4.9739e-02, -2.3092e-02,  4.9584e-02, -3.0772e-02,  2.2959e-03,\n",
      "        -8.0192e-02,  4.0274e-02, -6.9788e-02, -5.4464e-05, -3.5675e-02,\n",
      "         6.2875e-02, -9.4103e-03,  7.0972e-03, -7.2548e-02,  7.6967e-02,\n",
      "        -1.6313e-02, -1.5385e-02,  1.8084e-02,  2.1068e-02,  7.5779e-02,\n",
      "         3.5592e-03, -1.4590e-02, -3.9447e-02,  3.0346e-03, -5.3411e-02,\n",
      "        -4.5420e-02,  1.1858e-02, -4.1184e-03,  1.6639e-02, -1.6565e-02,\n",
      "        -7.0928e-03,  4.4489e-02,  3.2532e-02, -1.3823e-02, -7.2889e-02,\n",
      "         5.1129e-02,  4.4438e-02,  4.6304e-02,  7.9697e-02,  7.8799e-02,\n",
      "        -3.7272e-02,  3.3856e-02,  5.1361e-03, -3.1822e-02, -4.9734e-02,\n",
      "        -4.7564e-02, -2.1266e-02, -6.6616e-02,  3.9890e-02, -3.8708e-02,\n",
      "        -1.9196e-02,  2.3171e-02, -1.5590e-02, -2.0499e-02, -1.3930e-02,\n",
      "        -7.9711e-02,  3.7509e-02,  3.0831e-02,  9.2233e-03, -6.8343e-03,\n",
      "        -4.6735e-02, -4.3986e-02,  7.1877e-02,  5.0543e-02, -4.7728e-02,\n",
      "        -7.8029e-03,  5.4517e-03, -1.5436e-02,  1.4394e-02,  7.7633e-03,\n",
      "        -4.0991e-02, -5.1461e-02, -3.4895e-02, -3.8257e-03,  7.2402e-02,\n",
      "         2.5021e-02, -5.2107e-02,  4.0404e-02, -6.3106e-02,  6.7381e-02,\n",
      "        -3.0187e-02,  7.9316e-02,  7.6265e-03,  6.6839e-02,  4.1833e-02,\n",
      "         3.6756e-02,  4.7131e-02,  9.4579e-03, -7.4735e-03, -4.9843e-02,\n",
      "        -2.5303e-02,  2.9585e-03,  7.4725e-03, -7.0074e-02, -5.0652e-02,\n",
      "        -1.6819e-02, -2.3142e-02, -5.3270e-02, -4.2774e-02,  4.3084e-02,\n",
      "         2.9349e-02,  8.2294e-02,  2.2028e-02,  2.2555e-02,  7.5592e-02,\n",
      "         3.1715e-02, -5.9087e-02,  2.1459e-02, -5.7688e-02, -6.6935e-02,\n",
      "        -5.1093e-03,  5.7133e-02,  6.6819e-02,  6.9847e-02, -5.0160e-02,\n",
      "         4.3342e-02, -1.8145e-02, -5.7420e-02, -6.8088e-02, -3.8071e-03,\n",
      "         6.0233e-02, -4.0597e-02,  1.9265e-02,  6.2011e-02,  7.0372e-02,\n",
      "        -6.0413e-02,  4.0997e-02, -6.2867e-02, -8.0388e-02,  5.3175e-02,\n",
      "        -2.3603e-02, -2.8010e-02, -5.7891e-02, -2.2408e-02, -5.4363e-02,\n",
      "         7.4120e-02,  4.1665e-02], requires_grad=True))\n",
      "('output.weight', Parameter containing:\n",
      "tensor([[ 0.0407,  0.0163,  0.0307,  ..., -0.0037,  0.0243, -0.0049],\n",
      "        [ 0.0338,  0.0067,  0.0113,  ...,  0.0290, -0.0037, -0.0421],\n",
      "        [-0.0071,  0.0190, -0.0230,  ..., -0.0127, -0.0377,  0.0423],\n",
      "        ...,\n",
      "        [ 0.0155,  0.0168, -0.0201,  ..., -0.0124,  0.0183, -0.0230],\n",
      "        [-0.0346, -0.0189,  0.0259,  ...,  0.0221,  0.0270,  0.0128],\n",
      "        [ 0.0102,  0.0311,  0.0107,  ..., -0.0371,  0.0351,  0.0385]],\n",
      "       requires_grad=True))\n",
      "('output.bias', Parameter containing:\n",
      "tensor([-0.0335, -0.0208,  0.0145, -0.0435,  0.0101, -0.0017, -0.0089, -0.0327,\n",
      "        -0.0039, -0.0164], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for param in model.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4b296ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SFN import SFN\n",
    "opt = SFN(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb842c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Parameter containing:\n",
      "tensor([[-0.0625, -0.0451, -0.0572,  ...,  0.0195, -0.0308,  0.0798],\n",
      "        [ 0.0273,  0.0594, -0.0430,  ..., -0.0543, -0.0601, -0.0516],\n",
      "        [ 0.0570, -0.0605, -0.0404,  ..., -0.0569,  0.0216, -0.0678],\n",
      "        ...,\n",
      "        [ 0.0643, -0.0566, -0.0621,  ..., -0.0296,  0.0460, -0.0806],\n",
      "        [ 0.0040,  0.0394, -0.0167,  ...,  0.0114,  0.0195,  0.0399],\n",
      "        [ 0.0396,  0.0744, -0.0017,  ...,  0.0508, -0.0338, -0.0091]],\n",
      "       requires_grad=True)\n",
      "------------------\n",
      "None\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for group in opt.param_groups:\n",
    "    print(type(group['params']))\n",
    "    for p in group['params']:\n",
    "        if i == 0:\n",
    "            print(p)\n",
    "            print('------------------')\n",
    "            print(p.grad)\n",
    "            print('------------------')\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee692a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0625, -0.0451, -0.0572,  ..., -0.0327, -0.0039, -0.0164],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([p.view(-1) for group in opt.param_groups for p in group['params']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64ea216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0117eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(train_dataset)\n",
    "bh = int(n_train ** 0.5)\n",
    "bsz = 128\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=bsz, shuffle=True)\n",
    "train_dataloader_hess = DataLoader(train_dataset, batch_size=bh, shuffle=True) # Used for updating the preconditioner\n",
    "train_dataloader2 = DataLoader(train_dataset, batch_size=4096, shuffle=False) # Used for computing metrics on the training set\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4096, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85e8a4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataloader:\n",
    "    opt.zero_grad()\n",
    "    y_hat = model(x)\n",
    "    loss = loss_fn(y_hat, y)\n",
    "    break\n",
    "\n",
    "# Backward pass to compute gradients\n",
    "loss.backward()\n",
    "# grad_tuple = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
    "\n",
    "# Extract gradients\n",
    "params = []\n",
    "for group in opt.param_groups:\n",
    "    for param in group['params']:\n",
    "        params.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "882e6f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_h, y_h in train_dataloader_hess:\n",
    "    y_h_hat = model(x_h)\n",
    "    l_h = loss_fn(y_h_hat, y_h)\n",
    "    break\n",
    "grad_tuple = torch.autograd.grad(l_h, model.parameters(), create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42673dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_params = []\n",
    "for gradient in grad_tuple:\n",
    "    if gradient is not None:\n",
    "        grad_params.append(gradient)\n",
    "# grad_params = torch.cat([gradient.view(-1) for gradient in grad_tuple if gradient is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7818e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [\n",
    "    torch.randn_like(p)\n",
    "    for p in grad_params\n",
    "]\n",
    "# augment the vector with a scalar\n",
    "v.append(torch.randint(2, (1,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de181f",
   "metadata": {},
   "source": [
    "### _fvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d860f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhessian.utils import group_product, group_add, normalization, get_params_grad, orthnormal\n",
    "from opt_utils import group_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcdf88de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Compute Hessian-vector product\n",
    "Hv = opt._hvp(grad_params, params, v[:-1])\n",
    "\n",
    "# Multiply the last element of v with grad_params\n",
    "tg = group_scalar(grad_params, v[-1])\n",
    "tg = [tgi.detach() for tgi in tg]\n",
    "\n",
    "# Compute gTv\n",
    "gTv = group_product(grad_params, v[:-1]).detach()\n",
    "\n",
    "output = group_add(Hv, tg)\n",
    "output.append(gTv - opt.delta * v[-1])\n",
    "\n",
    "print(type(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de2b78e",
   "metadata": {},
   "source": [
    "### appx_min_eigvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53d501e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for group in opt.param_groups:\n",
    "    for param in group['params']:\n",
    "        params.append(param)\n",
    "\n",
    "gradsH = []\n",
    "for gradient in grad_tuple:\n",
    "    if gradient is not None:\n",
    "        gradsH.append(gradient)\n",
    "\n",
    "device = params[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5478f6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randint(2, (1,))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a8f69eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [\n",
    "    torch.randint_like(p, high=2, device=device)\n",
    "    for p in params\n",
    "]\n",
    "# generate Rademacher random variables\n",
    "for v_i in v:\n",
    "    v_i[v_i == 0] = -1\n",
    "# augment the vector with a scalar\n",
    "v.append(torch.randint(2, (1,), device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "402da0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [v_i.reshape(-1) for v_i in v]\n",
    "w = torch.cat(w)\n",
    "w = w/torch.norm(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffd3da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = normalization(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fa1962b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0352,  0.0352,  0.0352,  ...,  0.0352, -0.0352, -0.0352],\n",
      "        [ 0.0352,  0.0352,  0.0352,  ...,  0.0352, -0.0352, -0.0352],\n",
      "        [ 0.0352, -0.0352,  0.0352,  ...,  0.0352, -0.0352,  0.0352],\n",
      "        ...,\n",
      "        [-0.0352,  0.0352,  0.0352,  ..., -0.0352,  0.0352,  0.0352],\n",
      "        [ 0.0352, -0.0352,  0.0352,  ...,  0.0352,  0.0352, -0.0352],\n",
      "        [ 0.0352,  0.0352, -0.0352,  ..., -0.0352, -0.0352, -0.0352]])\n"
     ]
    }
   ],
   "source": [
    "vp = group_scalar(v, torch.tensor([10.0]))\n",
    "print(vp[2])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6a0ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_prime = [torch.zeros(p.size()).to(device) for p in params]\n",
    "w_prime.append(torch.zeros(1).to(device))   # add a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ece5cb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0137])\n"
     ]
    }
   ],
   "source": [
    "w_prime = opt._fvp(gradsH, params, v)\n",
    "print(w_prime[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de6f1892",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a4be4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate minimum eigenvalue = -1.946365237236023\n",
      "Min eigvec: tensor([-2.0281e-05,  3.2317e-06,  1.9437e-05,  ...,  1.2507e-03,\n",
      "        -6.6984e-04, -6.7602e-02])\n",
      "Min eigvec shape: torch.Size([80907])\n"
     ]
    }
   ],
   "source": [
    "opt.verbose = True\n",
    "min_val, vec = opt.appx_min_eigvec(gradsH, params, iter=100)\n",
    "print(\"Min eigvec:\", vec)\n",
    "print(\"Min eigvec shape:\", vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4058648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard Lanczos algorithm initialization\n",
    "v_list = [v]\n",
    "w_list = []\n",
    "alpha_list = []\n",
    "beta_list = []\n",
    "############### Lanczos\n",
    "for i in range(iter):\n",
    "    opt.zero_grad()\n",
    "    Fv = [torch.zeros(p.size()).to(device) for p in params]\n",
    "    Fv.append(torch.zeros(1).to(device))   # add a scalar\n",
    "    if i == 0:\n",
    "        Fv = opt._fvp(gradsH, params, v)\n",
    "        alpha = group_product(Fv, v)\n",
    "        alpha_list.append(alpha.cpu().item())\n",
    "        w = group_add(Fv, v, alpha=-alpha)\n",
    "        w_list.append(w)\n",
    "    else:\n",
    "        beta = torch.sqrt(group_product(w, w))\n",
    "        beta_list.append(beta.cpu().item())\n",
    "        if beta_list[-1] != 0.:\n",
    "            # We should re-orth it\n",
    "            v = orthnormal(w, v_list)\n",
    "            v_list.append(v)\n",
    "        else:\n",
    "            # generate a new vector\n",
    "            w = [torch.randn(p.size()).to(device) for p in params]\n",
    "            w.append(torch.randn(1).to(device))\n",
    "            v = orthnormal(w, v_list)\n",
    "            v_list.append(v)\n",
    "        Fv = opt._fvp(gradsH, params, v)\n",
    "        alpha = group_product(Fv, v)\n",
    "        alpha_list.append(alpha.cpu().item())\n",
    "        w_tmp = group_add(Fv, v, alpha=-alpha)\n",
    "        w = group_add(w_tmp, v_list[-2], alpha=-beta)\n",
    "\n",
    "T = torch.zeros(iter, iter).to(device)\n",
    "for i in range(len(alpha_list)):\n",
    "    T[i, i] = alpha_list[i]\n",
    "    if i < len(alpha_list) - 1:\n",
    "        T[i + 1, i] = beta_list[i]\n",
    "        T[i, i + 1] = beta_list[i]\n",
    "eigvals, eigvecs_T = torch.linalg.eigh(T)\n",
    "V = torch.stack([torch.cat([v_i.reshape(-1) for v_i in v]) for v in v_list])\n",
    "min_eigvec = torch.mv(V.t(), eigvecs_T[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98aaf727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min eigval: tensor(-1.9462)\n",
      "Min eigvec: tensor([-1.1366e-05,  9.1092e-06,  9.8557e-06,  ...,  1.3235e-03,\n",
      "        -7.0513e-04, -7.2199e-02])\n",
      "Min eigvec shape: torch.Size([80907])\n"
     ]
    }
   ],
   "source": [
    "print(\"Min eigval:\", eigvals[0])\n",
    "print(\"Min eigvec:\",min_eigvec)\n",
    "print(\"Min eigvec shape:\", min_eigvec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "605422f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sy/f_pvhwlj30x1zk3j1ppfsbbw0000gn/T/ipykernel_48255/2345899080.py:5: MatplotlibDeprecationWarning: Auto-close()ing of figures upon backend switching is deprecated since 3.8 and will be removed two minor releases later.  To suppress this warning, explicitly call plt.close('all') first.\n",
      "  matplotlib.use('TkAgg')\n"
     ]
    }
   ],
   "source": [
    "from pyhessian import hessian, get_esd_plot # Hessian computation\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "251d0889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ycchu/miniconda3/envs/pykan-env/lib/python3.9/site-packages/torch/autograd/__init__.py:251: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /Users/runner/miniforge3/conda-bld/libtorch_1715184395080/work/torch/csrc/autograd/engine.cpp:1176.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataloader:\n",
    "    hessian_comp = hessian(model, loss_fn, data=(x,y), cuda=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9140751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top Hessian eigenvalue of this model is 4.9525\n"
     ]
    }
   ],
   "source": [
    "top_eigenvalues, top_eigenvector = hessian_comp.eigenvalues()\n",
    "print(\"The top Hessian eigenvalue of this model is %.4f\"%top_eigenvalues[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4f8277c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ycchu/Documents/Research/KAN/code/pykan2/pykan/pyhessian/density_plot.py:66: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  density_output[i, j] = np.sum(tmp_result * weights[i, :])\n"
     ]
    }
   ],
   "source": [
    "pdf = PdfPages('figures/spec_density/mlp.pdf')\n",
    "density_eigen, density_weight = hessian_comp.density()\n",
    "fig, ax = get_esd_plot(density_eigen, density_weight)\n",
    "ax.set_title(f'Spectrum of Hessian')\n",
    "pdf.savefig(fig, bbox_inches = 'tight')\n",
    "plt.close(fig)\n",
    "pdf.close()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
